{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning Based Heart Disease Prediction **"
      ],
      "metadata": {
        "id": "HPEfPXBoO8EZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the Dependecies**"
      ],
      "metadata": {
        "id": "RQoslpyaN5_x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-PqFSYsqLNgl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Collection and Processing**"
      ],
      "metadata": {
        "id": "DqRW1RdAOAPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the csv data to a Pandas DataFrame\n",
        "heart_data = pd.read_csv('heart_disease_data (1).csv')"
      ],
      "metadata": {
        "id": "xUlIP3w5Lcm3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the column names explicitly\n",
        "column_names = heart_data.columns.tolist()\n",
        "X = heart_data.drop(columns='target', axis=1)\n",
        "X.columns = column_names[:-1]  # Exclude the last column ('target') as it is the target variable\n"
      ],
      "metadata": {
        "id": "ZdCM_aOmLgXo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of rows and columns in the dataset\n",
        "heart_data.shape"
      ],
      "metadata": {
        "id": "YmuzadQWLoTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting some info about the data\n",
        "heart_data.info()"
      ],
      "metadata": {
        "id": "GdmmDAnrLrsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values\n",
        "heart_data.isnull().sum()"
      ],
      "metadata": {
        "id": "QsWFWvkSLvNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical measures about the data\n",
        "heart_data.describe()"
      ],
      "metadata": {
        "id": "DSCisOSRLxZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting the Features and Target**"
      ],
      "metadata": {
        "id": "TsItvtUZOQdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the target variable Y\n",
        "Y = heart_data['target']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n"
      ],
      "metadata": {
        "id": "ZWqDH_fuL92M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data using StandardScaler while keeping the column names\n",
        "scaler = StandardScaler()\n",
        "ct = ColumnTransformer(transformers=[('num', scaler, X.columns)])\n",
        "X_train_scaled = ct.fit_transform(X_train)\n",
        "X_test_scaled = ct.transform(X_test)\n"
      ],
      "metadata": {
        "id": "AWD3_dj1MGIZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ],
      "metadata": {
        "id": "YfSxvu4OObgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "Q2qGrbMmOf2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase the number of iterations for LogisticRegression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "# Training the LogisticRegression model with Training data\n",
        "model.fit(X_train_scaled, Y_train)"
      ],
      "metadata": {
        "id": "dPFWBo5aMIQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "XCXcPgGhOkQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8DOnXtBYgDLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Score**"
      ],
      "metadata": {
        "id": "_TZSQ7YlOnm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on training data\n",
        "X_train_prediction = model.predict(X_train_scaled)\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "print('Accuracy on Training data:', training_data_accuracy)"
      ],
      "metadata": {
        "id": "AgoCsdjUMbkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on test data\n",
        "X_test_prediction = model.predict(X_test_scaled)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "print('Accuracy on Test data:', test_data_accuracy)"
      ],
      "metadata": {
        "id": "LMdxRNOgNj-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building a Predictive System **"
      ],
      "metadata": {
        "id": "xEwqu2rQOrBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input data for prediction (using the scaled data)\n",
        "input_data = [57,\t0,\t0\t,120,\t354,\t0,\t1,\t163,\t1,\t0.6,\t2,\t0,\t2]\n",
        "\n",
        "# Convert the input data to a DataFrame and use the ColumnTransformer to scale it\n",
        "input_data_df = pd.DataFrame([input_data], columns=X.columns)\n",
        "input_data_scaled = ct.transform(input_data_df)\n",
        "\n",
        "prediction = model.predict(input_data_scaled)\n",
        "if prediction[0] == 0:\n",
        "    print('The Person does not have Heart Disease')\n",
        "else:\n",
        "    print('The Person has Heart Disease')"
      ],
      "metadata": {
        "id": "ElJSosmANogb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZdVFB40wO5kU"
      }
    }
  ]
}